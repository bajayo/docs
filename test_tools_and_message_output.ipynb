{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMudDFt7mRqA4rHo2gUpRW5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bajayo/docs/blob/master/test_tools_and_message_output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0Dkdi6Q89zN",
        "outputId": "54217c3e-2209-443d-8c4e-2a44a52bc436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==1.24.0 in /usr/local/lib/python3.10/dist-packages (1.24.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.24.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.24.0) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.24.0) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.24.0) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.24.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.24.0) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.24.0) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.24.0) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.24.0) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.24.0) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.24.0) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.24.0) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.24.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.24.0) (2.18.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Starting to run\n",
            "Run without streaming\n",
            "thread id = thread_6GvJ89JCRo3qf4uMPR4gDJKg\n",
            "message id = msg_3yuyi9OPPhX6ICD81cwevn4I\n",
            "run id = run_ZwjehDD5Q1btPK9EIEHwppQz\n",
            "run status= queued\n",
            "run status= in_progress\n",
            "run status= in_progress\n",
            "run status= in_progress\n",
            "run status= in_progress\n",
            "run status= in_progress\n",
            "run status= in_progress\n",
            "run status= in_progress\n",
            "run final status= requires_action\n",
            "required_action =  {\"submit_tool_outputs\":{\"tool_calls\":[{\"id\":\"call_r5EdghbIhbSR8rP5Onb7bR79\",\"function\":{\"arguments\":\"{\\\"title\\\":\\\"What is your age?\\\",\\\"text\\\":\\\"Please select the age range that applies to you. This information helps us tailor our responses to better suit your needs.\\\",\\\"id\\\":\\\"age\\\",\\\"summary\\\":\\\"The assistant asked the user for their age range to tailor responses better.\\\",\\\"type\\\":\\\"single_choice\\\",\\\"answers\\\":[{\\\"answer_text\\\":\\\"Under 18\\\",\\\"answer_id\\\":\\\"age_1\\\"},{\\\"answer_text\\\":\\\"18-24\\\",\\\"answer_id\\\":\\\"age_2\\\"},{\\\"answer_text\\\":\\\"25-34\\\",\\\"answer_id\\\":\\\"age_3\\\"},{\\\"answer_text\\\":\\\"35-44\\\",\\\"answer_id\\\":\\\"age_4\\\"},{\\\"answer_text\\\":\\\"45-54\\\",\\\"answer_id\\\":\\\"age_5\\\"},{\\\"answer_text\\\":\\\"55-64\\\",\\\"answer_id\\\":\\\"age_6\\\"},{\\\"answer_text\\\":\\\"65 or older\\\",\\\"answer_id\\\":\\\"age_7\\\"}]}\",\"name\":\"ask_question\"},\"type\":\"function\"}]},\"type\":\"submit_tool_outputs\"}\n",
            "messages =  {\"data\":[{\"id\":\"msg_XfjKLAk07gQKlk9XBnerJyNT\",\"assistant_id\":\"asst_d4mvnDcYwvTN9TewV4KYegjY\",\"attachments\":[],\"completed_at\":null,\"content\":[{\"text\":{\"annotations\":[],\"value\":\"this is a text response\"},\"type\":\"text\"}],\"created_at\":1714654649,\"incomplete_at\":null,\"incomplete_details\":null,\"metadata\":{},\"object\":\"thread.message\",\"role\":\"assistant\",\"run_id\":\"run_ZwjehDD5Q1btPK9EIEHwppQz\",\"status\":null,\"thread_id\":\"thread_6GvJ89JCRo3qf4uMPR4gDJKg\"},{\"id\":\"msg_3yuyi9OPPhX6ICD81cwevn4I\",\"assistant_id\":null,\"attachments\":[],\"completed_at\":null,\"content\":[{\"text\":{\"annotations\":[],\"value\":\"Please return a text response: \\\"this is a text response\\\" and a sample call the ask_question function, ask for my age. Please return both responses to this message. Start with the text response and follow with the tool_call (ask_question) response.\"},\"type\":\"text\"}],\"created_at\":1714654647,\"incomplete_at\":null,\"incomplete_details\":null,\"metadata\":{},\"object\":\"thread.message\",\"role\":\"user\",\"run_id\":null,\"status\":null,\"thread_id\":\"thread_6GvJ89JCRo3qf4uMPR4gDJKg\"}],\"object\":\"list\",\"first_id\":\"msg_XfjKLAk07gQKlk9XBnerJyNT\",\"last_id\":\"msg_3yuyi9OPPhX6ICD81cwevn4I\",\"has_more\":false}\n",
            "Run with streaming\n",
            "thread id = thread_7rz3xolXVUIAyKMBjiTOzyTB\n",
            "message id = msg_6CtwdU5yYTHMG8t2TzJAq4LY\n",
            "on_run_step_created: {\"id\":\"step_pKf3EJlCOIn7C0za9P1zsCOx\",\"assistant_id\":\"asst_d4mvnDcYwvTN9TewV4KYegjY\",\"cancelled_at\":null,\"completed_at\":null,\"created_at\":1714654662,\"expired_at\":null,\"failed_at\":null,\"last_error\":null,\"metadata\":null,\"object\":\"thread.run.step\",\"run_id\":\"run_waUx4ClAdgZwfKHaHJzhrthg\",\"status\":\"in_progress\",\"step_details\":{\"message_creation\":{\"message_id\":\"msg_566coJimK4fMZ7SloEbmSDE1\"},\"type\":\"message_creation\"},\"thread_id\":\"thread_7rz3xolXVUIAyKMBjiTOzyTB\",\"type\":\"message_creation\",\"usage\":null,\"expires_at\":1714655260}\n",
            "on_text_created: this\n",
            "on_text_done: text = this is a text response\n",
            "on_run_step_done: run step = {\"id\":\"step_pKf3EJlCOIn7C0za9P1zsCOx\",\"assistant_id\":\"asst_d4mvnDcYwvTN9TewV4KYegjY\",\"cancelled_at\":null,\"completed_at\":1714654663,\"created_at\":1714654662,\"expired_at\":null,\"failed_at\":null,\"last_error\":null,\"metadata\":null,\"object\":\"thread.run.step\",\"run_id\":\"run_waUx4ClAdgZwfKHaHJzhrthg\",\"status\":\"completed\",\"step_details\":{\"message_creation\":{\"message_id\":\"msg_566coJimK4fMZ7SloEbmSDE1\"},\"type\":\"message_creation\"},\"thread_id\":\"thread_7rz3xolXVUIAyKMBjiTOzyTB\",\"type\":\"message_creation\",\"usage\":{\"completion_tokens\":7,\"prompt_tokens\":1771,\"total_tokens\":1778},\"expires_at\":1714655260}\n",
            "on_run_step_created: {\"id\":\"step_AZtzrDcAcBA2Wan8oLCaXm3K\",\"assistant_id\":\"asst_d4mvnDcYwvTN9TewV4KYegjY\",\"cancelled_at\":null,\"completed_at\":null,\"created_at\":1714654663,\"expired_at\":null,\"failed_at\":null,\"last_error\":null,\"metadata\":null,\"object\":\"thread.run.step\",\"run_id\":\"run_waUx4ClAdgZwfKHaHJzhrthg\",\"status\":\"in_progress\",\"step_details\":{\"tool_calls\":[],\"type\":\"tool_calls\"},\"thread_id\":\"thread_7rz3xolXVUIAyKMBjiTOzyTB\",\"type\":\"tool_calls\",\"usage\":null,\"expires_at\":1714655260}\n",
            "on_tool_call_created: tool call = {\"id\":\"call_MD8B4g56AhDDB9ZCiMlH76lM\",\"function\":{\"arguments\":\"\",\"name\":\"ask_question\",\"output\":null},\"type\":\"function\",\"index\":0}\n",
            "on_tool_call_done: tool call = {\"id\":\"call_MD8B4g56AhDDB9ZCiMlH76lM\",\"function\":{\"arguments\":\"{\\\"title\\\":\\\"What is your age?\\\",\\\"text\\\":\\\"Please select the age range that best describes you.\\\",\\\"id\\\":\\\"age\\\",\\\"tooltip\\\":\\\"Your age helps us to provide more personalized assistance.\\\",\\\"summary\\\":\\\"The assistant asked for the user's age to provide personalized assistance. Possible answers include 'age_1': '18-29', 'age_2': '30-39', 'age_3': '40-49', 'age_4': '50+.'\\\",\\\"type\\\":\\\"single_choice\\\",\\\"answers\\\":[{\\\"answer_text\\\":\\\"18-29\\\",\\\"answer_id\\\":\\\"age_1\\\"},{\\\"answer_text\\\":\\\"30-39\\\",\\\"answer_id\\\":\\\"age_2\\\"},{\\\"answer_text\\\":\\\"40-49\\\",\\\"answer_id\\\":\\\"age_3\\\"},{\\\"answer_text\\\":\\\"50+\\\",\\\"answer_id\\\":\\\"age_4\\\"}]}\",\"name\":\"ask_question\",\"output\":null},\"type\":\"function\",\"index\":0}\n",
            "on_end\n"
          ]
        }
      ],
      "source": [
        "# Install openai package - specify the version here. For the first test use \"1.7.1\", for the second \"1.9.0\".\n",
        "!pip install openai==1.24.0\n",
        "!pip install nest_asyncio\n",
        "\n",
        "# Import required libraries\n",
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from openai import AsyncAssistantEventHandler\n",
        "from openai.types.beta.threads.runs import RunStep, ToolCall\n",
        "from typing_extensions import override\n",
        "import nest_asyncio\n",
        "\n",
        "# create an assystant with the following setup:\n",
        "# instructions:\n",
        "# You are a python 3.11 Full Stack Developer assistant. You are a fastAPI, Cloud, Google Cloud, expert.\n",
        "# The user interacts with you while building and testing a Business Cloud infrastructure layer that delivers advanced AI capabilities to the organization's employees.\n",
        "# Your job is to support the development team that works on that infrastructure when testing, troubleshooting, debugging and creating new features and applications on the platform.\n",
        "# The user may ask to simulate various responses for mimicking various scenarios. You should follow the user's instructions and generate exactly the output requested.\n",
        "# The developer may ask you to return text, files, function calls or any combination of them.\n",
        "\n",
        "\n",
        "# model: gpt-4-turbo-preview\n",
        "\n",
        "# enable File search\n",
        "# enable Code interpreter\n",
        "\n",
        "\n",
        "# add the following function\n",
        "ask_question_function = {\n",
        "  \"name\": \"ask_question\",\n",
        "  \"description\": \"This function should always be triggered for asking the user any question.\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"title\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The title of the question that should be presented to the user.\"\n",
        "      },\n",
        "      \"text\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The text of the question that should be presented to the user.\"\n",
        "      },\n",
        "      \"id\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"An identifier representing the question. For example 'age'.\"\n",
        "      },\n",
        "      \"tooltip\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"A text describing the question and its purpose.\"\n",
        "      },\n",
        "      \"summary\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"A textual summary of the question and answers that will be used for providing the context to the next call to the ai engine. For example: The assistant asked to provide age range, the question id is 'age', the possible answers are: 'age_1': '18-40', 'age_2': '41+'.\"\n",
        "      },\n",
        "      \"type\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The type of the question. The options are: 'single_choice': the user can only choose one answer, 'multi_choice': the user may select more than one answer\"\n",
        "      },\n",
        "      \"answers\": {\n",
        "        \"type\": \"object\",\n",
        "        \"description\": \"A list of all the possible answer objects.\",\n",
        "        \"properties\": {\n",
        "          \"answer_text\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The text that the user should see.\"\n",
        "          },\n",
        "          \"answer_id\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"An id representing the answer in the following structure: {question_id}_{number}\"\n",
        "          },\n",
        "          \"answer_tooltip\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"A text describing the answer.\"\n",
        "          }\n",
        "        },\n",
        "        \"required\": [\n",
        "          \"answer_text\",\n",
        "          \"answer_id\"\n",
        "        ]\n",
        "      }\n",
        "    },\n",
        "    \"required\": [\n",
        "      \"title\",\n",
        "      \"text\",\n",
        "      \"id\",\n",
        "      \"summary\",\n",
        "      \"type\",\n",
        "      \"answers\"\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "# Import required libraries\n",
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "\n",
        "# Your API_KEY and ASSISTANT_ID go here\n",
        "API_KEY = \"your_api_key_here\"\n",
        "ASSISTANT_ID = \"your_assistant_id_here\" # use the one you created\n",
        "\n",
        "# Apply the patch to allow nested event loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# The main coroutine for asynchronous execution\n",
        "async def main():\n",
        "    # Initialize the AsyncOpenAI client\n",
        "    client = AsyncOpenAI(\n",
        "        api_key=API_KEY\n",
        "    )\n",
        "\n",
        "    content = \"Please return a text response: \\\"this is a text response\\\" and a sample call the ask_question function, ask for my age. Please return both responses to this message. Start with the text response and follow with the tool_call (ask_question) response.\"\n",
        "    ##############################################################################\n",
        "    # 1 - No streaming\n",
        "    # Create a thread\n",
        "    print(\"Run without streaming\")\n",
        "    thread = await client.beta.threads.create()\n",
        "    print(f\"thread id = {thread.id}\")\n",
        "    # Add a message to the thread\n",
        "    message = await client.beta.threads.messages.create(\n",
        "        thread_id=thread.id,\n",
        "        role=\"user\",\n",
        "        content=content\n",
        "    )\n",
        "    print(f\"message id = {message.id}\")\n",
        "\n",
        "    # Run the assistant\n",
        "    run = await client.beta.threads.runs.create(\n",
        "        thread_id=thread.id,\n",
        "        assistant_id=ASSISTANT_ID\n",
        "    )\n",
        "    print(f\"run id = {run.id}\")\n",
        "\n",
        "    # Poll run status\n",
        "    while run.status not in [\"completed\", \"requires_action\", \"cancelled\", \"failed\", \"expired\"]:\n",
        "        print(f\"run status= {run.status}\")\n",
        "        run = await client.beta.threads.runs.retrieve(\n",
        "            thread_id=thread.id,\n",
        "            run_id=run.id\n",
        "        )\n",
        "        await asyncio.sleep(1)  # wait 1 sec\n",
        "    print(f\"run final status= {run.status}\")\n",
        "    # when status is \"requires_action\"\n",
        "    if run.status == \"requires_action\":\n",
        "        print(\"required_action = \", run.required_action.json())\n",
        "\n",
        "    # When run status is \"completed\" or \"requires_action\", print the message output.\n",
        "    messages = await client.beta.threads.messages.list(\n",
        "                thread_id=thread.id\n",
        "            )\n",
        "    print(\"messages = \", messages.json())\n",
        "\n",
        "    ##############################################################################\n",
        "    # 2 - with streaming:\n",
        "    print(\"Run with streaming\")\n",
        "    thread = await client.beta.threads.create()\n",
        "    print(f\"thread id = {thread.id}\")\n",
        "\n",
        "    # Add a message to the thread\n",
        "    message = await client.beta.threads.messages.create(\n",
        "        thread_id=thread.id,\n",
        "        role=\"user\",\n",
        "        content=content\n",
        "    )\n",
        "    print(f\"message id = {message.id}\")\n",
        "\n",
        "    event_handler = EventHandler()\n",
        "\n",
        "    async with client.beta.threads.runs.stream(\n",
        "          thread_id=thread.id,\n",
        "          assistant_id=ASSISTANT_ID,\n",
        "          event_handler=event_handler\n",
        "    ) as stream:\n",
        "      await stream.until_done()\n",
        "\n",
        "\n",
        "\n",
        "class EventHandler(AsyncAssistantEventHandler):\n",
        "\n",
        "    @override\n",
        "    async def on_text_created(self, text) -> None:\n",
        "        print(f\"on_text_created: {text.value}\")\n",
        "\n",
        "    @override\n",
        "    async def on_text_done(self, text) -> None:\n",
        "        print(f\"on_text_done: text = {text.value}\")\n",
        "\n",
        "    @override\n",
        "    async def on_run_step_created(self, run_step: RunStep):\n",
        "        print(f\"on_run_step_created: {run_step.json()}\")\n",
        "\n",
        "    @override\n",
        "    async def on_run_step_done(self, run_step: RunStep):\n",
        "        print(f\"on_run_step_done: run step = {run_step.json()}\")\n",
        "\n",
        "\n",
        "    @override\n",
        "    async def on_tool_call_created(self, tool_call: ToolCall):\n",
        "        print(f\"on_tool_call_created: tool call = {tool_call.json()}\")\n",
        "\n",
        "    @override\n",
        "    async def on_tool_call_done(self, tool_call):\n",
        "        print(f\"on_tool_call_done: tool call = {tool_call.json()}\")\n",
        "\n",
        "    @override\n",
        "    async def on_end(self):\n",
        "        print(\"on_end\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Starting to run\")\n",
        "\n",
        "# Get the current loop and run the main coroutine\n",
        "loop = asyncio.get_event_loop()\n",
        "loop.run_until_complete(main())"
      ]
    }
  ]
}