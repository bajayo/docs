{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj1olu3pgywqkHPKB8/NM6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bajayo/docs/blob/master/test_tools_and_message_output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0Dkdi6Q89zN",
        "outputId": "7cb6994e-f1c8-44d8-fa68-21351f309e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==1.24.0 in /usr/local/lib/python3.10/dist-packages (1.24.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.24.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.24.0) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.24.0) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.24.0) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.24.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.24.0) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.24.0) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.24.0) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.24.0) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.24.0) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.24.0) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.24.0) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.24.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.24.0) (2.18.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Starting to run\n",
            "Run without streaming\n",
            "thread id = thread_RoNRcQglIfoRGFOvprgXKde0\n",
            "message id = msg_96WY532PJK25NgyowwQ3zcPj\n",
            "run id = run_Yk3Z1xH32LsBa6mEaEizu2ZG\n",
            "run status= queued\n",
            "run status= in_progress\n",
            "run status= in_progress\n",
            "run status= in_progress\n",
            "run status= in_progress\n",
            "run status= in_progress\n",
            "run final status= requires_action\n",
            "messages =  {\"data\":[{\"id\":\"msg_neUyFe5WerSNqpivEnHb5deu\",\"assistant_id\":\"asst_d4mvnDcYwvTN9TewV4KYegjY\",\"attachments\":[],\"completed_at\":null,\"content\":[{\"text\":{\"annotations\":[],\"value\":\"this is a text response\"},\"type\":\"text\"}],\"created_at\":1714650948,\"incomplete_at\":null,\"incomplete_details\":null,\"metadata\":{},\"object\":\"thread.message\",\"role\":\"assistant\",\"run_id\":\"run_Yk3Z1xH32LsBa6mEaEizu2ZG\",\"status\":null,\"thread_id\":\"thread_RoNRcQglIfoRGFOvprgXKde0\"},{\"id\":\"msg_96WY532PJK25NgyowwQ3zcPj\",\"assistant_id\":null,\"attachments\":[],\"completed_at\":null,\"content\":[{\"text\":{\"annotations\":[],\"value\":\"Please return a text response: \\\"this is a text response\\\" and a sample call the ask_question function, ask for my age. Please return both responses to this message. Start with the text response and follow with the tool_call (ask_question) response.\"},\"type\":\"text\"}],\"created_at\":1714650947,\"incomplete_at\":null,\"incomplete_details\":null,\"metadata\":{},\"object\":\"thread.message\",\"role\":\"user\",\"run_id\":null,\"status\":null,\"thread_id\":\"thread_RoNRcQglIfoRGFOvprgXKde0\"}],\"object\":\"list\",\"first_id\":\"msg_neUyFe5WerSNqpivEnHb5deu\",\"last_id\":\"msg_96WY532PJK25NgyowwQ3zcPj\",\"has_more\":false}\n",
            "Run with streaming\n",
            "thread id = thread_4whRrFJJKJCnnLhi72kGNx0s\n",
            "message id = msg_SzAgOzm7fhbj8rRFE4ArbuKX\n",
            "on_run_step_created: {\"id\":\"step_JDotPLJlCnyFQhDT7V1xNGX4\",\"assistant_id\":\"asst_d4mvnDcYwvTN9TewV4KYegjY\",\"cancelled_at\":null,\"completed_at\":null,\"created_at\":1714650958,\"expired_at\":null,\"failed_at\":null,\"last_error\":null,\"metadata\":null,\"object\":\"thread.run.step\",\"run_id\":\"run_oKZ5VGXMvGLw1PUfuzKhuRCV\",\"status\":\"in_progress\",\"step_details\":{\"message_creation\":{\"message_id\":\"msg_S4tycdO6pvcWjWrGR59n4u0M\"},\"type\":\"message_creation\"},\"thread_id\":\"thread_4whRrFJJKJCnnLhi72kGNx0s\",\"type\":\"message_creation\",\"usage\":null,\"expires_at\":1714651557}\n",
            "on_text_created: this\n",
            "on_text_done: text = this is a text response\n",
            "on_run_step_done: run step = {\"id\":\"step_JDotPLJlCnyFQhDT7V1xNGX4\",\"assistant_id\":\"asst_d4mvnDcYwvTN9TewV4KYegjY\",\"cancelled_at\":null,\"completed_at\":1714650960,\"created_at\":1714650958,\"expired_at\":null,\"failed_at\":null,\"last_error\":null,\"metadata\":null,\"object\":\"thread.run.step\",\"run_id\":\"run_oKZ5VGXMvGLw1PUfuzKhuRCV\",\"status\":\"completed\",\"step_details\":{\"message_creation\":{\"message_id\":\"msg_S4tycdO6pvcWjWrGR59n4u0M\"},\"type\":\"message_creation\"},\"thread_id\":\"thread_4whRrFJJKJCnnLhi72kGNx0s\",\"type\":\"message_creation\",\"usage\":{\"completion_tokens\":7,\"prompt_tokens\":1771,\"total_tokens\":1778},\"expires_at\":1714651557}\n",
            "on_run_step_created: {\"id\":\"step_ZXft63Kh4kl1I82BT589wNTt\",\"assistant_id\":\"asst_d4mvnDcYwvTN9TewV4KYegjY\",\"cancelled_at\":null,\"completed_at\":null,\"created_at\":1714650960,\"expired_at\":null,\"failed_at\":null,\"last_error\":null,\"metadata\":null,\"object\":\"thread.run.step\",\"run_id\":\"run_oKZ5VGXMvGLw1PUfuzKhuRCV\",\"status\":\"in_progress\",\"step_details\":{\"tool_calls\":[],\"type\":\"tool_calls\"},\"thread_id\":\"thread_4whRrFJJKJCnnLhi72kGNx0s\",\"type\":\"tool_calls\",\"usage\":null,\"expires_at\":1714651557}\n",
            "on_tool_call_created: tool call = {\"id\":\"call_FPOqwmuFwyZz9QRYkdrTS8S4\",\"function\":{\"arguments\":\"\",\"name\":\"ask_question\",\"output\":null},\"type\":\"function\",\"index\":0}\n",
            "on_tool_call_done: tool call = {\"id\":\"call_FPOqwmuFwyZz9QRYkdrTS8S4\",\"function\":{\"arguments\":\"{\\\"id\\\":\\\"age\\\",\\\"text\\\":\\\"How old are you?\\\",\\\"title\\\":\\\"Your Age\\\",\\\"tooltip\\\":\\\"We are gathering this information for demographic analysis.\\\",\\\"type\\\":\\\"single_choice\\\",\\\"summary\\\":\\\"The assistant asked the user to provide their age.\\\",\\\"answers\\\":[{\\\"answer_id\\\":\\\"age_1\\\",\\\"answer_text\\\":\\\"18-24\\\"},{\\\"answer_id\\\":\\\"age_2\\\",\\\"answer_text\\\":\\\"25-34\\\"},{\\\"answer_id\\\":\\\"age_3\\\",\\\"answer_text\\\":\\\"35-44\\\"},{\\\"answer_id\\\":\\\"age_4\\\",\\\"answer_text\\\":\\\"45-54\\\"},{\\\"answer_id\\\":\\\"age_5\\\",\\\"answer_text\\\":\\\"55-64\\\"},{\\\"answer_id\\\":\\\"age_6\\\",\\\"answer_text\\\":\\\"65+\\\"}]}\",\"name\":\"ask_question\",\"output\":null},\"type\":\"function\",\"index\":0}\n",
            "on_end\n"
          ]
        }
      ],
      "source": [
        "# Install openai package - specify the version here. For the first test use \"1.7.1\", for the second \"1.9.0\".\n",
        "!pip install openai==1.24.0\n",
        "!pip install nest_asyncio\n",
        "\n",
        "# Import required libraries\n",
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from openai import AsyncAssistantEventHandler\n",
        "from openai.types.beta.threads.runs import RunStep, ToolCall\n",
        "from typing_extensions import override\n",
        "import nest_asyncio\n",
        "\n",
        "# create an assystant with the following setup:\n",
        "# instructions:\n",
        "# You are a python 3.11 Full Stack Developer assistant. You are a fastAPI, Cloud, Google Cloud, expert.\n",
        "# The user interacts with you while building and testing a Business Cloud infrastructure layer that delivers advanced AI capabilities to the organization's employees.\n",
        "# Your job is to support the development team that works on that infrastructure when testing, troubleshooting, debugging and creating new features and applications on the platform.\n",
        "# The user may ask to simulate various responses for mimicking various scenarios. You should follow the user's instructions and generate exactly the output requested.\n",
        "# The developer may ask you to return text, files, function calls or any combination of them.\n",
        "\n",
        "\n",
        "# model: gpt-4-turbo-preview\n",
        "\n",
        "# enable File search\n",
        "# enable Code interpreter\n",
        "\n",
        "\n",
        "# add the following function\n",
        "ask_question_function = {\n",
        "  \"name\": \"ask_question\",\n",
        "  \"description\": \"This function should always be triggered for asking the user any question.\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"title\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The title of the question that should be presented to the user.\"\n",
        "      },\n",
        "      \"text\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The text of the question that should be presented to the user.\"\n",
        "      },\n",
        "      \"id\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"An identifier representing the question. For example 'age'.\"\n",
        "      },\n",
        "      \"tooltip\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"A text describing the question and its purpose.\"\n",
        "      },\n",
        "      \"summary\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"A textual summary of the question and answers that will be used for providing the context to the next call to the ai engine. For example: The assistant asked to provide age range, the question id is 'age', the possible answers are: 'age_1': '18-40', 'age_2': '41+'.\"\n",
        "      },\n",
        "      \"type\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The type of the question. The options are: 'single_choice': the user can only choose one answer, 'multi_choice': the user may select more than one answer\"\n",
        "      },\n",
        "      \"answers\": {\n",
        "        \"type\": \"object\",\n",
        "        \"description\": \"A list of all the possible answer objects.\",\n",
        "        \"properties\": {\n",
        "          \"answer_text\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The text that the user should see.\"\n",
        "          },\n",
        "          \"answer_id\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"An id representing the answer in the following structure: {question_id}_{number}\"\n",
        "          },\n",
        "          \"answer_tooltip\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"A text describing the answer.\"\n",
        "          }\n",
        "        },\n",
        "        \"required\": [\n",
        "          \"answer_text\",\n",
        "          \"answer_id\"\n",
        "        ]\n",
        "      }\n",
        "    },\n",
        "    \"required\": [\n",
        "      \"title\",\n",
        "      \"text\",\n",
        "      \"id\",\n",
        "      \"summary\",\n",
        "      \"type\",\n",
        "      \"answers\"\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "# Import required libraries\n",
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "\n",
        "# Your API_KEY and ASSISTANT_ID go here\n",
        "API_KEY = \"your_api_key_here\"\n",
        "ASSISTANT_ID = \"your_new_assistant_id_here\" # use the one you created\n",
        "\n",
        "# Apply the patch to allow nested event loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# The main coroutine for asynchronous execution\n",
        "async def main():\n",
        "    # Initialize the AsyncOpenAI client\n",
        "    client = AsyncOpenAI(\n",
        "        api_key=API_KEY\n",
        "    )\n",
        "\n",
        "    content = \"Please return a text response: \\\"this is a text response\\\" and a sample call the ask_question function, ask for my age. Please return both responses to this message. Start with the text response and follow with the tool_call (ask_question) response.\"\n",
        "    ##############################################################################\n",
        "    # 1 - No streaming\n",
        "    # Create a thread\n",
        "    print(\"Run without streaming\")\n",
        "    thread = await client.beta.threads.create()\n",
        "    print(f\"thread id = {thread.id}\")\n",
        "    # Add a message to the thread\n",
        "    message = await client.beta.threads.messages.create(\n",
        "        thread_id=thread.id,\n",
        "        role=\"user\",\n",
        "        content=content\n",
        "    )\n",
        "    print(f\"message id = {message.id}\")\n",
        "\n",
        "    # Run the assistant\n",
        "    run = await client.beta.threads.runs.create(\n",
        "        thread_id=thread.id,\n",
        "        assistant_id=ASSISTANT_ID\n",
        "    )\n",
        "    print(f\"run id = {run.id}\")\n",
        "\n",
        "    # Poll run status\n",
        "    while run.status not in [\"completed\", \"requires_action\", \"cancelled\", \"failed\", \"expired\"]:\n",
        "        print(f\"run status= {run.status}\")\n",
        "        run = await client.beta.threads.runs.retrieve(\n",
        "            thread_id=thread.id,\n",
        "            run_id=run.id\n",
        "        )\n",
        "        await asyncio.sleep(1)  # wait 1 sec\n",
        "    print(f\"run final status= {run.status}\")\n",
        "\n",
        "    # When run status is \"completed\" or \"requires_action\", print the output.\n",
        "    messages = await client.beta.threads.messages.list(\n",
        "                thread_id=thread.id\n",
        "            )\n",
        "    print(\"messages = \", messages.json())\n",
        "\n",
        "    ##############################################################################\n",
        "    # 2 - with streaming:\n",
        "    print(\"Run with streaming\")\n",
        "    thread = await client.beta.threads.create()\n",
        "    print(f\"thread id = {thread.id}\")\n",
        "\n",
        "    # Add a message to the thread\n",
        "    message = await client.beta.threads.messages.create(\n",
        "        thread_id=thread.id,\n",
        "        role=\"user\",\n",
        "        content=content\n",
        "    )\n",
        "    print(f\"message id = {message.id}\")\n",
        "\n",
        "    event_handler = EventHandler()\n",
        "\n",
        "    async with client.beta.threads.runs.stream(\n",
        "          thread_id=thread.id,\n",
        "          assistant_id=ASSISTANT_ID,\n",
        "          event_handler=event_handler\n",
        "    ) as stream:\n",
        "      await stream.until_done()\n",
        "\n",
        "\n",
        "\n",
        "class EventHandler(AsyncAssistantEventHandler):\n",
        "\n",
        "    @override\n",
        "    async def on_text_created(self, text) -> None:\n",
        "        print(f\"on_text_created: {text.value}\")\n",
        "\n",
        "    @override\n",
        "    async def on_text_done(self, text) -> None:\n",
        "        print(f\"on_text_done: text = {text.value}\")\n",
        "\n",
        "    @override\n",
        "    async def on_run_step_created(self, run_step: RunStep):\n",
        "        print(f\"on_run_step_created: {run_step.json()}\")\n",
        "\n",
        "    @override\n",
        "    async def on_run_step_done(self, run_step: RunStep):\n",
        "        print(f\"on_run_step_done: run step = {run_step.json()}\")\n",
        "\n",
        "\n",
        "    @override\n",
        "    async def on_tool_call_created(self, tool_call: ToolCall):\n",
        "        print(f\"on_tool_call_created: tool call = {tool_call.json()}\")\n",
        "\n",
        "    @override\n",
        "    async def on_tool_call_done(self, tool_call):\n",
        "        print(f\"on_tool_call_done: tool call = {tool_call.json()}\")\n",
        "\n",
        "    @override\n",
        "    async def on_end(self):\n",
        "        print(\"on_end\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Starting to run\")\n",
        "\n",
        "# Get the current loop and run the main coroutine\n",
        "loop = asyncio.get_event_loop()\n",
        "loop.run_until_complete(main())"
      ]
    }
  ]
}